{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Before start you should be to install JAVA\n",
    "spark = (SparkSession\n",
    ".builder\n",
    ".appName(\"Weather-Atlas\")\n",
    ".getOrCreate()) # Entry-point to PySpark App\n",
    "\n",
    "# If click A- [above] or B - [below] in VSC hepls to add code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Formatted Date: string (nullable = true)\n",
      " |-- Summary: string (nullable = true)\n",
      " |-- Precip Type: string (nullable = true)\n",
      " |-- Temperature (C): string (nullable = true)\n",
      " |-- Apparent Temperature (C): string (nullable = true)\n",
      " |-- Humidity: string (nullable = true)\n",
      " |-- Wind Speed (km/h): string (nullable = true)\n",
      " |-- Wind Bearing (degrees): string (nullable = true)\n",
      " |-- Visibility (km): string (nullable = true)\n",
      " |-- Loud Cover: string (nullable = true)\n",
      " |-- Pressure (millibars): string (nullable = true)\n",
      " |-- Daily Summary: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read of DataFrame with auto identification of schema\n",
    "df = spark.read.format(\"csv\").option('header', \"true\").load(\"../dataset/weatherHistory.csv\")\n",
    "\n",
    "df.printSchema() # Help to explore schema of DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+-----------+-----------------+------------------------+--------+------------------+----------------------+------------------+----------+--------------------+--------------------+\n",
      "|      Formatted Date|      Summary|Precip Type|  Temperature (C)|Apparent Temperature (C)|Humidity| Wind Speed (km/h)|Wind Bearing (degrees)|   Visibility (km)|Loud Cover|Pressure (millibars)|       Daily Summary|\n",
      "+--------------------+-------------+-----------+-----------------+------------------------+--------+------------------+----------------------+------------------+----------+--------------------+--------------------+\n",
      "|2006-04-01 00:00:...|Partly Cloudy|       rain|9.472222222222221|      7.3888888888888875|    0.89|           14.1197|                 251.0|15.826300000000002|       0.0|             1015.13|Partly cloudy thr...|\n",
      "|2006-04-01 01:00:...|Partly Cloudy|       rain|9.355555555555558|       7.227777777777776|    0.86|           14.2646|                 259.0|15.826300000000002|       0.0|             1015.63|Partly cloudy thr...|\n",
      "|2006-04-01 02:00:...|Mostly Cloudy|       rain|9.377777777777778|       9.377777777777778|    0.89|3.9284000000000003|                 204.0|           14.9569|       0.0|             1015.94|Partly cloudy thr...|\n",
      "|2006-04-01 03:00:...|Partly Cloudy|       rain| 8.28888888888889|       5.944444444444446|    0.83|           14.1036|                 269.0|15.826300000000002|       0.0|             1016.41|Partly cloudy thr...|\n",
      "|2006-04-01 04:00:...|Mostly Cloudy|       rain|8.755555555555553|       6.977777777777779|    0.83|           11.0446|                 259.0|15.826300000000002|       0.0|             1016.51|Partly cloudy thr...|\n",
      "|2006-04-01 05:00:...|Partly Cloudy|       rain|9.222222222222221|        7.11111111111111|    0.85|           13.9587|                 258.0|           14.9569|       0.0|             1016.66|Partly cloudy thr...|\n",
      "|2006-04-01 06:00:...|Partly Cloudy|       rain|7.733333333333334|       5.522222222222221|    0.95|           12.3648|                 259.0| 9.982000000000001|       0.0|             1016.72|Partly cloudy thr...|\n",
      "+--------------------+-------------+-----------+-----------------+------------------------+--------+------------------+----------------------+------------------+----------+--------------------+--------------------+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exploration of WEATHER DATA\n",
    "df.show(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------------------------\n",
      " Formatted Date           | 2006-04-01 00:00:... \n",
      " Summary                  | Partly Cloudy        \n",
      " Precip Type              | rain                 \n",
      " Temperature (C)          | 9.472222222222221    \n",
      " Apparent Temperature (C) | 7.3888888888888875   \n",
      " Humidity                 | 0.89                 \n",
      " Wind Speed (km/h)        | 14.1197              \n",
      " Wind Bearing (degrees)   | 251.0                \n",
      " Visibility (km)          | 15.826300000000002   \n",
      " Loud Cover               | 0.0                  \n",
      " Pressure (millibars)     | 1015.13              \n",
      " Daily Summary            | Partly cloudy thr... \n",
      "-RECORD 1----------------------------------------\n",
      " Formatted Date           | 2006-04-01 01:00:... \n",
      " Summary                  | Partly Cloudy        \n",
      " Precip Type              | rain                 \n",
      " Temperature (C)          | 9.355555555555558    \n",
      " Apparent Temperature (C) | 7.227777777777776    \n",
      " Humidity                 | 0.86                 \n",
      " Wind Speed (km/h)        | 14.2646              \n",
      " Wind Bearing (degrees)   | 259.0                \n",
      " Visibility (km)          | 15.826300000000002   \n",
      " Loud Cover               | 0.0                  \n",
      " Pressure (millibars)     | 1015.63              \n",
      " Daily Summary            | Partly cloudy thr... \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count of State of Atmosphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|             Summary|count|\n",
      "+--------------------+-----+\n",
      "|              Breezy|   54|\n",
      "|Humid and Mostly ...|   40|\n",
      "|  Windy and Overcast|   45|\n",
      "|               Foggy| 7148|\n",
      "|Humid and Partly ...|   17|\n",
      "|     Windy and Foggy|    4|\n",
      "|Breezy and Partly...|  386|\n",
      "|                 Dry|   34|\n",
      "|       Partly Cloudy|31733|\n",
      "|               Clear|10890|\n",
      "|       Mostly Cloudy|28094|\n",
      "|    Breezy and Foggy|   35|\n",
      "| Breezy and Overcast|  528|\n",
      "|Dangerously Windy...|    1|\n",
      "|Breezy and Mostly...|  516|\n",
      "|Windy and Partly ...|   67|\n",
      "|               Windy|    8|\n",
      "|Dry and Partly Cl...|   86|\n",
      "|Windy and Mostly ...|   35|\n",
      "|            Overcast|16597|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Summary\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|      Summary| Temp|\n",
      "+-------------+-----+\n",
      "|Partly Cloudy|9.472|\n",
      "|Partly Cloudy|9.356|\n",
      "|Mostly Cloudy|9.378|\n",
      "|Partly Cloudy|8.289|\n",
      "|Mostly Cloudy|8.756|\n",
      "+-------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "df.select(\"Summary\", F.round(\"Temperature (C)\", 3).alias(\"Temp\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|      Formatted Date|\n",
      "+--------------------+\n",
      "|2006-08-17 15:00:...|\n",
      "|2006-08-23 19:00:...|\n",
      "|2006-12-27 14:00:...|\n",
      "|2006-12-27 15:00:...|\n",
      "|2006-07-15 19:00:...|\n",
      "|2006-07-16 16:00:...|\n",
      "|2006-07-17 10:00:...|\n",
      "|2006-07-19 01:00:...|\n",
      "|2006-07-04 12:00:...|\n",
      "|2006-05-13 23:00:...|\n",
      "|2006-10-12 13:00:...|\n",
      "|2007-04-09 16:00:...|\n",
      "|2007-07-14 21:00:...|\n",
      "|2007-06-22 12:00:...|\n",
      "|2007-06-23 09:00:...|\n",
      "+--------------------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the fist 15-entries where visibility above 15\n",
    "\n",
    "df.select(F.col(\"Formatted Date\")).where(F.col(\"Visibility (km)\") > 15).show(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+\n",
      "|Precip Type|    Temperature (C)|\n",
      "+-----------+-------------------+\n",
      "|       snow|-10.305555555555555|\n",
      "|       snow|-11.083333333333334|\n",
      "|       snow|-10.805555555555555|\n",
      "|       snow|-11.822222222222223|\n",
      "|       snow|-11.855555555555556|\n",
      "+-----------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df\n",
    ".select(\"Precip Type\", \"Temperature (C)\")\n",
    ".filter(F.col(\"Precip Type\") == \"snow\")\n",
    ".filter(F.col(\"Temperature (C)\") <= -10)\n",
    ".show(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|             Summary|count|\n",
      "+--------------------+-----+\n",
      "|       Partly Cloudy|31733|\n",
      "|       Mostly Cloudy|28094|\n",
      "|            Overcast|16597|\n",
      "|               Clear|10890|\n",
      "|               Foggy| 7148|\n",
      "| Breezy and Overcast|  528|\n",
      "|Breezy and Mostly...|  516|\n",
      "|Breezy and Partly...|  386|\n",
      "+--------------------+-----+\n",
      "only showing top 8 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    df\n",
    "    .groupBy(\"Summary\")\n",
    "    .count()\n",
    "    .orderBy(F.col(\"count\").desc())\n",
    "    .show(8)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+------------------+\n",
      "|             Summary|count|            min_temp|          max_temp|\n",
      "+--------------------+-----+--------------------+------------------+\n",
      "|       Partly Cloudy|31733|-0.00555555555555...| 9.994444444444447|\n",
      "|       Mostly Cloudy|28094|-0.00555555555555...| 9.994444444444447|\n",
      "|            Overcast|16597|-0.00555555555555...| 9.994444444444447|\n",
      "|               Clear|10890|-0.00555555555555...| 9.994444444444447|\n",
      "|               Foggy| 7148|-0.00555555555555...| 9.994444444444447|\n",
      "| Breezy and Overcast|  528|-0.03888888888888905| 6.661111111111112|\n",
      "|Breezy and Mostly...|  516|-0.13333333333333247| 6.527777777777778|\n",
      "|Breezy and Partly...|  386|-0.00555555555555...| 6.611111111111111|\n",
      "|Dry and Partly Cl...|   86|                20.0| 35.67222222222222|\n",
      "|Windy and Partly ...|   67| -0.7111111111111117| 5.977777777777777|\n",
      "|          Light Rain|   63|  10.166666666666664|  8.11111111111111|\n",
      "|              Breezy|   54|-0.01666666666666...| 5.738888888888888|\n",
      "|  Windy and Overcast|   45| -0.7666666666666662| 5.977777777777777|\n",
      "|Humid and Mostly ...|   40|                20.0|23.111111111111107|\n",
      "|             Drizzle|   39|   10.02222222222222| 7.216666666666669|\n",
      "|    Breezy and Foggy|   35| -10.005555555555553|6.3611111111111125|\n",
      "|Windy and Mostly ...|   35| -2.5222222222222217| 5.877777777777776|\n",
      "|                 Dry|   34|                20.0| 36.62222222222223|\n",
      "|Humid and Partly ...|   17|  20.055555555555554| 23.56666666666667|\n",
      "|Dry and Mostly Cl...|   14|   20.07222222222222| 31.61111111111111|\n",
      "+--------------------+-----+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'coalesce'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\23\\Desktop\\start-pyspark\\atlas-weather\\atlas.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/23/Desktop/start-pyspark/atlas-weather/atlas.ipynb#ch0000011?line=33'>34</a>\u001b[0m     save_dataset(outcome)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/23/Desktop/start-pyspark/atlas-weather/atlas.ipynb#ch0000011?line=34'>35</a>\u001b[0m     \u001b[39m#spark.stop()\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/23/Desktop/start-pyspark/atlas-weather/atlas.ipynb#ch0000011?line=36'>37</a>\u001b[0m main()\n",
      "\u001b[1;32mc:\\Users\\23\\Desktop\\start-pyspark\\atlas-weather\\atlas.ipynb Cell 12'\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/23/Desktop/start-pyspark/atlas-weather/atlas.ipynb#ch0000011?line=31'>32</a>\u001b[0m df \u001b[39m=\u001b[39m extract_dataset(spark)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/23/Desktop/start-pyspark/atlas-weather/atlas.ipynb#ch0000011?line=32'>33</a>\u001b[0m outcome \u001b[39m=\u001b[39m transform_dataset(df)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/23/Desktop/start-pyspark/atlas-weather/atlas.ipynb#ch0000011?line=33'>34</a>\u001b[0m save_dataset(outcome)\n",
      "\u001b[1;32mc:\\Users\\23\\Desktop\\start-pyspark\\atlas-weather\\atlas.ipynb Cell 12'\u001b[0m in \u001b[0;36msave_dataset\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/23/Desktop/start-pyspark/atlas-weather/atlas.ipynb#ch0000011?line=25'>26</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msave_dataset\u001b[39m(df: DataFrame) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/23/Desktop/start-pyspark/atlas-weather/atlas.ipynb#ch0000011?line=26'>27</a>\u001b[0m     df\u001b[39m.\u001b[39;49mcoalesce(\u001b[39m4\u001b[39m)\u001b[39m.\u001b[39mwrite\u001b[39m.\u001b[39mmode(\u001b[39m\"\u001b[39m\u001b[39moverwrite\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mformat(\u001b[39m\"\u001b[39m\u001b[39mjson\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39moutcome.json\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'coalesce'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "import pyspark.sql.types as t\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "\n",
    "def extract_dataset(spark: SparkSession) -> DataFrame:\n",
    "    url = \"../dataset/weatherHistory.csv\"\n",
    "    return spark.read.option(\"header\", 'true').csv(url)\n",
    "\n",
    "\n",
    "def transform_dataset(df: DataFrame) -> DataFrame:\n",
    "    outcome = (\n",
    "        df\n",
    "        .groupBy(\"Summary\")\n",
    "        .agg(\n",
    "            f.count(\"Summary\").alias(\"count\"),\n",
    "            f.min(\"Apparent Temperature (C)\").alias(\"min_temp\"),\n",
    "            f.max(\"Apparent Temperature (C)\").alias(\"max_temp\")\n",
    "        )\n",
    "        .orderBy(f.col(\"count\").desc())\n",
    "    ).show()\n",
    "\n",
    "    return outcome\n",
    "\n",
    "\n",
    "def save_dataset(df: DataFrame) -> None:\n",
    "    df.coalesce(4).write.mode(\"overwrite\").format(\"json\").save(\"outcome.json\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    spark = SparkSession.builder.appName(\"Weather-Atlas2\").getOrCreate()\n",
    "    df = extract_dataset(spark)\n",
    "    outcome = transform_dataset(df)\n",
    "    save_dataset(outcome)\n",
    "    #spark.stop()\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "92db4a3e6462b9fadf0a0f8c62912623cebd408e910f4b1d99e22ed15ce59dca"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
